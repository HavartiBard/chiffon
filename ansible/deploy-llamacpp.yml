- name: Deploy llama.cpp from GHCR
  hosts: windows_gpu
  gather_facts: false
  vars:
    ghcr_owner: HavartiBard
    ghcr_image_name: chiffon-llamacpp
    ghcr_tag: latest
    ghcr_registry: ghcr.io
    compose_dir: "{{ ansible_env.HOME | default('/home/james') }}/chiffon"
    ghcr_image: "{{ ghcr_registry }}/{{ ghcr_owner }}/{{ ghcr_image_name }}:{{ ghcr_tag }}"
  tasks:
    - name: Ensure chiffon root directory exists
      file:
        path: "{{ compose_dir }}"
        state: directory

    - name: Ensure model directory exists
      file:
        path: "{{ compose_dir }}/models"
        state: directory

    - name: Ensure cache directory exists
      file:
        path: "{{ compose_dir }}/cache"
        state: directory

    - name: Upload GHCR-aware docker-compose
      template:
        src: ansible/templates/docker-compose.ghcr.yml.j2
        dest: "{{ compose_dir }}/docker-compose.yml"

    - name: Pull llama.cpp image from GHCR
      shell: |
        docker pull {{ ghcr_image }}
      args:
        chdir: "{{ compose_dir }}"

    - name: Start llama.cpp stack
      shell: |
        docker compose -f docker-compose.yml up -d
      args:
        chdir: "{{ compose_dir }}"
