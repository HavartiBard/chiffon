# Phase 6 Plan 01: Infrastructure Agent Foundation

---
phase: 06-infrastructure-agent
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/agents/infra_agent/__init__.py
  - src/agents/infra_agent/agent.py
  - src/agents/infra_agent/playbook_discovery.py
  - src/common/models.py
  - alembic/versions/005_playbook_cache.py
  - tests/test_infra_agent_foundation.py
autonomous: true
must_haves:
  truths:
    - "InfraAgent class exists and extends BaseAgent"
    - "PlaybookDiscovery scans ~/CascadeProjects/homelab-infra/ansible for playbooks"
    - "Playbook metadata (service, description, variables, tags) is extracted"
    - "Cache TTL of 1 hour is enforced with auto-refresh"
    - "Invalid playbooks are skipped with logged errors"
  artifacts:
    - path: "src/agents/infra_agent/agent.py"
      provides: "InfraAgent class extending BaseAgent"
      exports: ["InfraAgent"]
    - path: "src/agents/infra_agent/playbook_discovery.py"
      provides: "PlaybookDiscovery service"
      exports: ["PlaybookDiscovery", "PlaybookMetadata"]
    - path: "alembic/versions/005_playbook_cache.py"
      provides: "Database migration for playbook cache"
  key_links:
    - from: "src/agents/infra_agent/agent.py"
      to: "src/agents/base.py"
      via: "class inheritance"
      pattern: "class InfraAgent\\(BaseAgent\\)"
    - from: "src/agents/infra_agent/agent.py"
      to: "src/agents/infra_agent/playbook_discovery.py"
      via: "composition"
      pattern: "PlaybookDiscovery"
---

<objective>
Create the Infrastructure Agent foundation: the InfraAgent class that extends BaseAgent, and the PlaybookDiscovery service that scans ~/CascadeProjects/homelab-infra/ansible for Ansible playbooks with lazy loading and caching.

Purpose: This forms the core of Phase 6 - the agent that accepts deployment tasks from the orchestrator. Without the discovery mechanism, we cannot map tasks to playbooks.

Output: Working InfraAgent that can connect to RabbitMQ and a PlaybookDiscovery service that catalogs available playbooks with metadata extraction.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-infrastructure-agent/06-CONTEXT.md
@.planning/phases/06-infrastructure-agent/06-RESEARCH.md
@src/agents/base.py
@src/agents/desktop_agent.py
@src/common/models.py
@src/common/protocol.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create InfraAgent class</name>
  <files>
    src/agents/infra_agent/__init__.py
    src/agents/infra_agent/agent.py
  </files>
  <action>
Create the InfraAgent class that extends BaseAgent:

1. Create src/agents/infra_agent/__init__.py with exports: InfraAgent

2. Create src/agents/infra_agent/agent.py:
   - Import BaseAgent from src/agents/base
   - Import PlaybookDiscovery from .playbook_discovery
   - Import Config, WorkRequest, WorkResult from src/common

3. InfraAgent class:
   - __init__(agent_id: str, config: Config, repo_path: str = "~/CascadeProjects/homelab-infra/ansible"):
     - Call super().__init__(agent_id, "infra", config)
     - Initialize self.playbook_discovery = PlaybookDiscovery(repo_path)
     - Initialize self.repo_path = Path(repo_path).expanduser()

   - get_agent_capabilities() -> dict[str, Any]:
     - Return {"run_playbook": True, "discover_playbooks": True, "generate_template": True, "analyze_playbook": True}

   - async execute_work(work_request: WorkRequest) -> WorkResult:
     - Stub implementation for now (will be completed in Plan 03)
     - Log the work_type and parameters
     - Return WorkResult with status="completed", exit_code=0, output="InfraAgent stub - execution in Plan 03"

   - async discover_playbooks(force_refresh: bool = False) -> list[dict]:
     - Call self.playbook_discovery.discover_playbooks(force_refresh)
     - Return the catalog

   - async get_playbook_catalog() -> list[dict]:
     - Return cached playbooks via self.playbook_discovery.get_cached_catalog()

Follow the DesktopAgent pattern for structure but with infra-specific capabilities.
  </action>
  <verify>
    - [ ] src/agents/infra_agent/__init__.py exists with InfraAgent export
    - [ ] InfraAgent extends BaseAgent
    - [ ] get_agent_capabilities returns correct capability dict
    - [ ] Python imports work: `from src.agents.infra_agent import InfraAgent`
  </verify>
  <done>InfraAgent class created with BaseAgent inheritance and capability reporting</done>
</task>

<task type="auto">
  <name>Task 2: Create PlaybookDiscovery service</name>
  <files>
    src/agents/infra_agent/playbook_discovery.py
  </files>
  <action>
Create the PlaybookDiscovery service for lazy playbook scanning with caching:

1. Create src/agents/infra_agent/playbook_discovery.py

2. PlaybookMetadata Pydantic model:
   - path: str (full path to playbook)
   - filename: str (just the filename)
   - service: Optional[str] (extracted service name)
   - description: Optional[str] (from playbook header or name field)
   - required_vars: list[str] (variables defined in vars: section)
   - tags: list[str] (tags from playbook)
   - discovered_at: datetime (when this was scanned)

3. PlaybookDiscovery class:
   - __init__(repo_path: str, cache_ttl_seconds: int = 3600):
     - self.repo_path = Path(repo_path).expanduser()
     - self.cache_ttl = timedelta(seconds=cache_ttl_seconds)
     - self._cache: dict[str, PlaybookMetadata] = {}
     - self._cache_time: Optional[datetime] = None
     - self._yaml = YAML() (from ruamel.yaml)

   - async discover_playbooks(force_refresh: bool = False) -> list[PlaybookMetadata]:
     - Check cache validity: if not force_refresh and cache is valid (within TTL), return cached
     - Scan repo_path recursively for *.yml and *.yaml files
     - For each file, call _extract_metadata() with try/except (skip invalid, log warning)
     - Update cache with results
     - Return list of PlaybookMetadata

   - def get_cached_catalog() -> list[PlaybookMetadata]:
     - Return list(self._cache.values()) if cache exists, else empty list

   - def is_cache_valid() -> bool:
     - Return True if _cache_time is set and (now - _cache_time) < cache_ttl

   - async _extract_metadata(playbook_path: Path) -> Optional[PlaybookMetadata]:
     - Parse YAML with ruamel.yaml (preserves comments)
     - Extract service from:
       a. Header comment with format "# chiffon:service=xxx" (if present)
       b. Filename pattern: kuma-deploy.yml -> service="kuma"
     - Extract description from:
       a. Header comment with format "# chiffon:description=xxx"
       b. First play's "name:" field
     - Extract required_vars from first play's "vars:" section keys
     - Extract tags from first play's "tags:" field
     - Return PlaybookMetadata or None if parsing fails

4. Use ruamel.yaml (not PyYAML) for parsing to preserve comments and enable metadata extraction from header comments.

5. Log errors at WARNING level for skipped playbooks, include path and error message.
  </action>
  <verify>
    - [ ] PlaybookMetadata model validates correctly
    - [ ] PlaybookDiscovery scans directory recursively
    - [ ] Service name extracted from filename pattern (e.g., kuma-deploy.yml -> "kuma")
    - [ ] Cache TTL enforced (1 hour default)
    - [ ] Invalid YAML files are skipped with warning logged
  </verify>
  <done>PlaybookDiscovery service created with lazy scanning, metadata extraction, and 1-hour cache TTL</done>
</task>

<task type="auto">
  <name>Task 3: Create database migration and tests</name>
  <files>
    alembic/versions/005_playbook_cache.py
    src/common/models.py
    tests/test_infra_agent_foundation.py
  </files>
  <action>
Create database migration for playbook caching and comprehensive tests:

1. Create alembic/versions/005_playbook_cache.py:
   - Table: playbook_cache
   - Columns:
     - id: Integer, primary key, autoincrement
     - playbook_path: String(500), unique, not null
     - service_name: String(100), nullable
     - description: Text, nullable
     - required_vars: JSONB, not null, default=[]
     - tags: JSONB, not null, default=[]
     - file_hash: String(64), not null (SHA256 for invalidation)
     - discovered_at: DateTime, not null
     - updated_at: DateTime, not null, onupdate=func.now()
   - Indexes:
     - idx_playbook_cache_service on service_name
     - idx_playbook_cache_path on playbook_path (unique)

2. Add PlaybookCache ORM model to src/common/models.py:
   - Match migration columns
   - Add __repr__ method

3. Create tests/test_infra_agent_foundation.py:
   - TestPlaybookMetadata: Pydantic model validation tests
   - TestPlaybookDiscovery:
     - test_scan_empty_directory: Returns empty list
     - test_scan_with_playbooks: Finds .yml and .yaml files
     - test_extract_service_from_filename: kuma-deploy.yml -> "kuma"
     - test_extract_vars_and_tags: Parse vars and tags from playbook
     - test_cache_ttl_enforced: Cache expires after TTL
     - test_force_refresh_ignores_cache: force_refresh=True rescans
     - test_invalid_yaml_skipped: Malformed YAML logged and skipped
   - TestInfraAgent:
     - test_agent_capabilities: Returns correct capabilities dict
     - test_agent_type_is_infra: agent_type == "infra"
     - test_discover_playbooks_delegation: Calls PlaybookDiscovery

4. Use pytest fixtures for temporary directories with sample playbooks.

5. Use pytest-asyncio for async test methods.
  </action>
  <verify>
    - [ ] Migration 005 runs without error: `alembic upgrade head`
    - [ ] PlaybookCache model added to models.py
    - [ ] All tests pass: `pytest tests/test_infra_agent_foundation.py -v`
    - [ ] Test coverage includes cache TTL, metadata extraction, error handling
  </verify>
  <done>Database migration for playbook cache created, ORM model added, comprehensive test suite passing</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. Run migration: `alembic upgrade head`
2. Run tests: `pytest tests/test_infra_agent_foundation.py -v`
3. Verify imports: `python -c "from src.agents.infra_agent import InfraAgent; print('Import OK')"`
4. Verify PlaybookDiscovery: `python -c "from src.agents.infra_agent.playbook_discovery import PlaybookDiscovery; print('Discovery OK')"`
</verification>

<success_criteria>
- InfraAgent class extends BaseAgent and reports infra capabilities
- PlaybookDiscovery scans ~/CascadeProjects/homelab-infra/ansible recursively
- Playbook metadata (service, description, vars, tags) extracted correctly
- Cache TTL of 1 hour enforced; force_refresh bypasses cache
- Invalid playbooks skipped with warning logged
- Database migration for playbook_cache table successful
- All tests pass (target: 20+ test cases)
</success_criteria>

<output>
After completion, create `.planning/phases/06-infrastructure-agent/06-01-SUMMARY.md`
</output>
